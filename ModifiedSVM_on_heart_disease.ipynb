{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yoUThuEtAXQw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6qV6oD3uAi4Y"
      },
      "outputs": [],
      "source": [
        "# Random state\n",
        "r=15\n",
        "ttt=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di_6_kQoAld9",
        "outputId": "ad9399e1-a2aa-435e-a9ec-7a8f0ba68149"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0  1  2    3    4  5  6    7  8    9  10 11 12 13\n",
            "1     52  1  0  125  212  0  1  168  0    1  2  2  3  0\n",
            "2     53  1  0  140  203  1  0  155  1  3.1  0  0  3  0\n",
            "3     70  1  0  145  174  0  1  125  1  2.6  0  0  3  0\n",
            "4     61  1  0  148  203  0  1  161  0    0  2  1  3  0\n",
            "5     62  0  0  138  294  1  1  106  0  1.9  1  3  2  0\n",
            "...   .. .. ..  ...  ... .. ..  ... ..  ... .. .. .. ..\n",
            "1021  59  1  1  140  221  0  1  164  1    0  2  0  2  1\n",
            "1022  60  1  0  125  258  0  0  141  1  2.8  1  1  3  0\n",
            "1023  47  1  0  110  275  0  0  118  1    1  1  1  2  0\n",
            "1024  50  0  0  110  254  0  0  159  0    0  2  0  2  1\n",
            "1025  54  1  0  120  188  0  1  113  0  1.4  1  1  3  0\n",
            "\n",
            "[1025 rows x 14 columns]\n",
            "      0  1  2    3    4  5  6    7  8    9  10 11 12\n",
            "1     52  1  0  125  212  0  1  168  0    1  2  2  3\n",
            "2     53  1  0  140  203  1  0  155  1  3.1  0  0  3\n",
            "3     70  1  0  145  174  0  1  125  1  2.6  0  0  3\n",
            "4     61  1  0  148  203  0  1  161  0    0  2  1  3\n",
            "5     62  0  0  138  294  1  1  106  0  1.9  1  3  2\n",
            "...   .. .. ..  ...  ... .. ..  ... ..  ... .. .. ..\n",
            "1021  59  1  1  140  221  0  1  164  1    0  2  0  2\n",
            "1022  60  1  0  125  258  0  0  141  1  2.8  1  1  3\n",
            "1023  47  1  0  110  275  0  0  118  1    1  1  1  2\n",
            "1024  50  0  0  110  254  0  0  159  0    0  2  0  2\n",
            "1025  54  1  0  120  188  0  1  113  0  1.4  1  1  3\n",
            "\n",
            "[1025 rows x 13 columns]\n",
            "---------------------------------------\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "       ..\n",
            "1021    1\n",
            "1022    0\n",
            "1023    0\n",
            "1024    1\n",
            "1025    0\n",
            "Name: 13, Length: 1025, dtype: object\n"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv('heart.csv', header=None)\n",
        "data.sample(frac=1)\n",
        "data=data.drop(0)\n",
        "X=data.drop(columns=[13],axis=1)\n",
        "\n",
        "Y=data[13]\n",
        "#--------------------------------main wt part---------------------------------------\n",
        "Y.replace('1', '1', inplace = True)\n",
        "print(data)\n",
        "print(X)\n",
        "print(\"---------------------------------------\")\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IM76xSFUAomK"
      },
      "outputs": [],
      "source": [
        "scaler=StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_train=scaler.transform(X)\n",
        "# X_test=scaler.transform(X_test)\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=ttt,stratify=Y,random_state=r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "As-f3IHPArqW",
        "outputId": "17b1b7a5-4f4a-4558-a92d-8e0591575cd5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=LinearRegression()\n",
        "model.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_2dbFzl_AwvH"
      },
      "outputs": [],
      "source": [
        "X_train_prediction=model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gXcCMBUA0Kj",
        "outputId": "a845c9cf-ed5e-43d9-e649-e67f752d466f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0  1  2    3    4  5  6    7  8    9  10 11 12 13          14\n",
            "1     52  1  0  125  212  0  1  168  0    1  2  2  3  0  335.640817\n",
            "2     53  1  0  140  203  1  0  155  1  3.1  0  0  3  0    7.424613\n",
            "3     70  1  0  145  174  0  1  125  1  2.6  0  0  3  0  -35.944028\n",
            "4     61  1  0  148  203  0  1  161  0    0  2  1  3  0  431.889160\n",
            "5     62  0  0  138  294  1  1  106  0  1.9  1  3  2  0  194.986606\n",
            "...   .. .. ..  ...  ... .. ..  ... ..  ... .. .. .. ..         ...\n",
            "1021  59  1  1  140  221  0  1  164  1    0  2  0  2  1  653.002229\n",
            "1022  60  1  0  125  258  0  0  141  1  2.8  1  1  3  0  -38.128040\n",
            "1023  47  1  0  110  275  0  0  118  1    1  1  1  2  0  158.358553\n",
            "1024  50  0  0  110  254  0  0  159  0    0  2  0  2  1  870.139597\n",
            "1025  54  1  0  120  188  0  1  113  0  1.4  1  1  3  0  173.066621\n",
            "\n",
            "[1025 rows x 15 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print(X_train_prediction)\n",
        "# for i in range (16):\n",
        "#   data[i]=X_train_prediction\n",
        "# for i in range (0):\n",
        "c=0\n",
        "for i in  X_train_prediction:\n",
        "  X_train_prediction[c]=i*1000  #---------------------------------------------------------------------------------------------------\n",
        "  c+=1\n",
        "data[14]=X_train_prediction\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAPEDDe3A2aP",
        "outputId": "a1889669-6160-4462-e767-b1bd354385f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n",
            "5       0\n",
            "       ..\n",
            "1021    1\n",
            "1022    0\n",
            "1023    0\n",
            "1024    1\n",
            "1025    0\n",
            "Name: 13, Length: 1025, dtype: object\n",
            "1.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Example of making predictions\n",
        "from multiprocessing import Process, Queue\n",
        "import logging\n",
        "import difflib, random, time\n",
        "import math\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "from itertools import repeat\n",
        "import multiprocessing as mp\n",
        "import time\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from csv import writer\n",
        "#for plotting\n",
        "plt.style.use('ggplot')\n",
        "from math import sqrt\n",
        "import multiprocessing\n",
        "from threading import Thread\n",
        "\n",
        "#feature weight change acc to no of row\n",
        "feature=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
        "feature[13]=0\n",
        "# feature[22]=0\n",
        "# feature[2]=0\n",
        "# feature[1]=0\n",
        "# calculate the Euclidean distance between two vectors\n",
        "def euclidean_distance(row1, row2):\n",
        "\tdistance = 0.0\n",
        "\tfor i in range(len(row1)-1):\n",
        "\t\tdistance += feature[i]*(row1[i] - row2[i])**2\n",
        "\treturn sqrt(distance)\n",
        "\n",
        "# Locate the most similar neighbors\n",
        "def get_neighbors(train, test_row, num_neighbors):\n",
        "  distances = list()\n",
        "  for train_row in train:\n",
        "    dist = euclidean_distance(test_row, train_row)\n",
        "    distances.append((train_row, dist))\n",
        "  distances.sort(key=lambda tup: tup[1])\n",
        "  neighbors = list()\n",
        "  for i in range(num_neighbors):\n",
        "    neighbors.append(distances[i][0])\n",
        "  \n",
        "  with open('event.csv', 'w') as f_object:\n",
        "    writer_object = writer(f_object)\n",
        " \n",
        "    # Pass the list as an argument into\n",
        "    # the writerow()\n",
        "    for list1 in neighbors:\n",
        "      writer_object.writerow(list1)\n",
        "\t\n",
        "    # Close the file object\n",
        "      # f_object.close()\n",
        "    return neighbors\n",
        "\n",
        "# Make a classification prediction with neighbors\n",
        "def predict_classification(train, test, num_neighbors,dataset):\n",
        "\t\n",
        "\t\tneighbors = get_neighbors(train, test, num_neighbors)\n",
        "\t\t# output_values = [row[-1] for row in neighbors]\n",
        "\t\t# print(test)\n",
        "\t\tdata=pd.DataFrame(neighbors)\n",
        "\t\tX=data.drop(columns=13,axis=1)\n",
        "\t\tY=data[13]\n",
        "\t\t# print(Y)\n",
        "\t\ttt=Y[0]\n",
        "\t\tprediction =tt\n",
        "\t\tu=5\n",
        "\t\tfor i in Y:\n",
        "\t\t\t\tif(i!=tt):\n",
        "\t\t\t\t\t\tu=9\n",
        "\t\tif(u==9):\n",
        "\t\t\t\t# Z=X[23]\n",
        "\t\t\t\t# print(Z)\n",
        "\t\t\t\t# X=X.drop(columns=23,axis=1)\n",
        "\n",
        "\t\t\t\t# scaler=StandardScaler()\t\t\t\t\n",
        "\t\t\t\t# scaler.fit(X)\n",
        "\t\t\t\t# X=scaler.transform(X)\n",
        "      # X_test=scaler.transform(X_test)\n",
        "\t\t\t\tmodel=svm.SVC(kernel='linear')\n",
        "\t\t\t\t# X[0][23]=Z\n",
        "\t\t\t\tmodel.fit(X,Y)\n",
        "\n",
        "\t\t\t\t# print(test[22])\n",
        "\t\t\t\tinput_data=(test[0:13]+test[14:])\n",
        "\t\t\t\tinput_data_as_numpy=np.asarray(input_data)\n",
        "\t\t\t\tinput_data_reshaped=input_data_as_numpy.reshape(1,-1)\n",
        "\t\t\t\t# input_data1=scaler.transform(input_data_reshaped)\n",
        "\t\t\t\t# input_data1[23]=input_data_reshaped[23]\n",
        "\t\t\t\tprediction=model.predict(input_data_reshaped)\n",
        "\n",
        "  # print(prediction,\" but expected \",test[0])\n",
        "\t\tif(math.floor(test[13])==math.floor(prediction)):\n",
        "\t\t\t\treturn 1\n",
        "\n",
        "\n",
        "\t\treturn 0\n",
        "\t\n",
        " \n",
        "\n",
        " \n",
        "def main():\n",
        "\t# Test distance function\n",
        "\t# df = pd.read_csv(r\"./letter.csv\")\n",
        "\t# # df=df.drop(columns=0,axis=1)\n",
        "\tX1=data\n",
        "  # Y1=data['status']\n",
        "\tX_train,X_test,Y_train,Y_test=train_test_split(X1,Y,test_size=ttt,stratify=Y,random_state=r)\n",
        "\tdataset = X_train.astype(float).values.tolist()\n",
        "\n",
        "\tX_test1 =X_test.astype(float).values.tolist()\n",
        "\tprint(data[13])\n",
        "\n",
        "\tp=[]\n",
        "\ts=[]\n",
        "\te=[]\n",
        "\ttotal=0\n",
        "\t# process=1   #--------------------------------------------------------------------------------------------process----------------------------------------------------\n",
        "\tfor i in X_test1:\n",
        "\t\t# print(i)\n",
        "\t\tp.append(predict_classification(dataset, i, 15,dataset))\n",
        "\n",
        "\t# for i in range(process):\n",
        "\t# \ts.append(time.perf_counter())\n",
        "\t# \tp[i].start()\n",
        "\t# for i in range(process):\n",
        "\t# \tp[i].join()\n",
        "\t# \te.append(time.perf_counter())\n",
        "\t# for i in range(process):\n",
        "\t# \ttotal=total+(e[i]-s[i])\n",
        "        \n",
        "\n",
        "\tresult=0\n",
        "\n",
        "\tfor i in range(205):\n",
        "\t\tresult+=p[i]\n",
        "\tresult=result/205;\n",
        "\tprint(result)\n",
        "\t# print(\"parallel Exec Time: \", e[process-1]-s[0])\n",
        "\t# print(\"total seq Exec Time: \", total)\n",
        "\t# print('Expected --%d' % (dataset[0][-1]))\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ciod0HuCA5YJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
