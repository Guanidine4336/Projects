{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "import math\n",
    "from math import sqrt\n",
    "from csv import writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 157\n",
    "ttt = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('glass.csv', header=None)\n",
    "print(data.shape)\n",
    "data = data.drop(0)\n",
    "data = data.sample(frac=1)\n",
    "X = data.drop(columns=9, axis=1)\n",
    "Y = data[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_train=scaler.transform(X)\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=ttt,random_state=r)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7436608916977974\n"
     ]
    }
   ],
   "source": [
    "X_train_prediction=model.predict(X)\n",
    "r2_scaled = r2_score(Y, X_train_prediction)\n",
    "print(r2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0      1     2     3      4     5      6     7     8  9   \\\n",
      "79   1.51613  13.92  3.52  1.25  72.88  0.37   7.94     0  0.14  2   \n",
      "63   1.52172  13.51  3.86  0.88  71.79  0.23   9.54     0  0.11  1   \n",
      "198  1.51727   14.7     0  2.34  73.28     0   8.95  0.66     0  7   \n",
      "113  1.52777  12.64     0  0.67  72.02  0.06   14.4     0     0  2   \n",
      "140  1.51674  12.87  3.56  1.64  73.14  0.65   7.99     0     0  2   \n",
      "..       ...    ...   ...   ...    ...   ...    ...   ...   ... ..   \n",
      "134    1.518  13.71  3.93  1.54  71.81  0.54   8.21     0  0.15  2   \n",
      "88   1.51645   13.4  3.49  1.52  72.65  0.67   8.08     0   0.1  2   \n",
      "132  1.52614   13.7     0  1.36  71.24  0.19  13.44     0   0.1  2   \n",
      "1    1.52101  13.64  4.49   1.1  71.78  0.06   8.75     0     0  1   \n",
      "123  1.51687  13.23  3.54  1.48  72.84  0.56    8.1     0     0  2   \n",
      "\n",
      "              10  \n",
      "79   2334.453703  \n",
      "63   1084.439027  \n",
      "198  7203.555891  \n",
      "113  2655.075894  \n",
      "140  2188.242612  \n",
      "..           ...  \n",
      "134  1838.090698  \n",
      "88   2183.762999  \n",
      "132  4082.927099  \n",
      "1    1128.955264  \n",
      "123  2093.143814  \n",
      "\n",
      "[214 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in  X_train_prediction:\n",
    "  X_train_prediction[c]=i*1000  \n",
    "  c+=1\n",
    "data[10]=X_train_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "#feature weight change acc to no of row\n",
    "feature=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "print(len(feature))\n",
    "feature[23]=1\n",
    "# feature[22]=0\n",
    "# feature[2]=0\n",
    "# feature[1]=0\n",
    "# calculate the Euclidean distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "\tdistance = 0.0\n",
    "\tfor i in range(len(row1)-1):\n",
    "\t\tdistance += feature[i]*(row1[i] - row2[i])**2\n",
    "\treturn sqrt(distance)\n",
    "\n",
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "  distances = list()\n",
    "  for train_row in train:\n",
    "    dist = euclidean_distance(test_row, train_row)\n",
    "    distances.append((train_row, dist))\n",
    "  distances.sort(key=lambda tup: tup[1])\n",
    "  neighbors = list()\n",
    "  for i in range(num_neighbors):\n",
    "    neighbors.append(distances[i][0])\n",
    "  \n",
    "  with open('event.csv', 'w') as f_object:\n",
    "    writer_object = writer(f_object)\n",
    " \n",
    "    # Pass the list as an argument into\n",
    "    # the writerow()\n",
    "    for list1 in neighbors:\n",
    "      writer_object.writerow(list1)\n",
    "\t\n",
    "    # Close the file object\n",
    "      # f_object.close()\n",
    "    return neighbors\n",
    "\n",
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(train, test, num_neighbors,dataset):\n",
    "\t\n",
    "\tneighbors = get_neighbors(train, test, num_neighbors)\n",
    "\t# output_values = [row[-1] for row in neighbors]\n",
    "\t# print(test)\n",
    "\tdata=pd.DataFrame(neighbors)\n",
    "\tX=data.drop(columns=9,axis=1)\n",
    "\t# print(X)\n",
    "\t# print(data)\n",
    "\tY=data[9]\n",
    "\ttt=Y[0]\n",
    "\t# print(f\"\\nHere comes first Y \\n{Y}\\n\")\n",
    "\tprediction = tt\n",
    "\tu=5\n",
    "\tfor i in Y:\n",
    "\t\tif(i!=tt):\n",
    "\t\t\tu=9\n",
    "\tif(u==9):\n",
    "\t\t\t# Z=X[23]\n",
    "\t\t# print(Z)\n",
    "\t\t# X=X.drop(columns=23,axis=1)\n",
    "\t\t# scaler=StandardScaler()\t\t\t\t\n",
    "\t\t# scaler.fit(X)\n",
    "\t\t# X=scaler.transform(X)\n",
    "\t\t# X_test=scaler.transform(X_test)\n",
    "\t\tmodel=svm.SVC(kernel='linear')\n",
    "\t\t# X[0][23]=Z\n",
    "\t\t# print(f\"\\nHere comes X\\n{X}\\nHere Comes Y\\n{Y}\")\n",
    "\t\tmodel.fit(X,Y)\n",
    "\t\t# # print(test[22])\n",
    "\t\tinput_data=(test[0:9]+test[10:])\n",
    "\t\t# print(input_data)\n",
    "\n",
    "\t\tinput_data_as_numpy=np.asarray(input_data)\n",
    "\t\tinput_data_reshaped=input_data_as_numpy.reshape(1,-1)\n",
    "\t\t# print(input_data_reshaped)\n",
    "\t\t# input_data1=scaler.transform(input_data_reshaped)\n",
    "\t\t# input_data1[23]=input_data_reshaped[23]\n",
    "\t\tprediction=model.predict(input_data_reshaped)\n",
    "\t\t# print(prediction,\" but expected \",test[0])\n",
    "\tif(math.floor(test[9])==math.floor(prediction)):\n",
    "\t\treturn 1\n",
    "\n",
    "\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(accuracy for j = 95: 60.46511627906976)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\t# Test distance function\n",
    "\t# df = pd.read_csv(r\"./letter.csv\")\n",
    "\t# # df=df.drop(columns=0,axis=1)\n",
    "\t# X1=data.drop(columns=[13],axis=1)\n",
    "\t# print(data[17])\n",
    "\t\n",
    "\n",
    "\t# process=1   #--------------------------------------------------------------------------------------------process----------------------------------------------------\n",
    "\t\n",
    "\t\n",
    "\tX1 = data\n",
    "\t# print(X1)\n",
    "\tX_train,X_test,Y_train,Y_test=train_test_split(X1,Y,test_size=ttt,random_state=r, stratify=Y)\n",
    "\tdataset = X_train.astype(float).values.tolist()\n",
    "\t# print((data.shape), len(dataset), len(dataset[0]))\n",
    "\tj = 95\n",
    "\tX_test1 =X_test.astype(float).values.tolist()\n",
    "\tp=[]\n",
    "\ts=[]\n",
    "\te=[]\n",
    "\ttotal=0\n",
    "\tfor i in X_test1:\n",
    "\t\tp.append(predict_classification(dataset, i,j,data))\n",
    "\tresult=0\n",
    "\tfor i in range(len(p)):\n",
    "\t\t# print(p[i])\n",
    "\t\tresult+=p[i]\n",
    "\tresult=result/len(p);\n",
    "\tprint(f\"(accuracy for j = {j}: {result*100})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
